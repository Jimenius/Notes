{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: AAAI\n",
    "\n",
    "Year: 2016\n",
    "\n",
    "Authors: Hado van Hasselt, Arthur Guez, David Silver\n",
    "\n",
    "Institutions: Google DeepMind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-learning is one of the most popular reinforcement learning algorithms, but it is known to sometimes learn unrealistically high action values because it includes a maximization step over estimated action values, which tends to prefer overestimated to underestimated values.\n",
    "\n",
    "Overoptimistic value estimates are not necessarily a problem in and of themselves. If all values would be uniformly higher then the relative action preferences are preserved and the resulting policy is not expected to be any worse. Furthermore, it is known that sometimes it is good to be optimistic: optimism in the face of uncertainty is a well-known exploration technique. If, however, the overestimations are not uniform and not concentrated at states to be learned more, then they might negatively affect the quality of the resulting policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Although not fully decoupled, the target network in the DQN architecture provides a natural candidate for the second value function, without having to introduce additional networks. It evaluates the greedy policy according to the online network, but uses the target network to estimate its value. Its update is the same as for DQN, but replacing the target with\n",
    "$$Y_t=R_{t+1}+\\gamma Q(S_{t+1},argmax_aQ(S_{t+1},a;\\theta_t),\\theta_t^-)$$\n",
    "$\\theta_t^-$ is the target netowrk for the evaluation of the current greedy policy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

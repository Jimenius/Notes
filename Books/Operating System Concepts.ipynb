{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Operating System Concepts</span>\n",
    "Authors: Avi Silberschatz, Peter Baer Galvin, Greg Gagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Chapter 3 Process Concept</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\">3.1 Process Concepts</span>\n",
    "A process includes the program code, the current activity, as represented by the value of the program counter and the contents of the processor's registers, the process stack, which contains temporary data (such as function parameters, return addresses, and local variables), a data section, which contains global variables, and a heap, which is memory thatis dynamically allocated during process run time.\n",
    "\n",
    "Although two processes may be associated with the same program, they are nevertheless considered two separate execution sequences. For instance, several users may be running different copies of the mail program, or the same user may invoke many copies of the Web browser program. Each of these is a separate process; and although the text sections are equivalent, the data, heap, and stack sections vary. It is also common to have a process that spawns many processes as it runs. \n",
    "\n",
    "As a proces::; excr:utes, it changes state. The state of a process is defil1.ed in part by the current activity of that process. Each process may be in one of the following states:\n",
    "- New: The process is being created.\n",
    "- Running: Instructions are being executed.\n",
    "- Waiting: The process is waiting for some event to occur (such as an I/0 completion or reception of a signal).\n",
    "- Ready: The process is waiting to be assigned to a processor.\n",
    "- Terminated: The process has finished execution.\n",
    "\n",
    "Each process is represented in the operating system by a process control block (PCB), also called a task control block.\n",
    "\n",
    "Modern operating systems have extended the process concept to allow a process to have multiple threads of execution and thus to perform more than one task at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\">3.2 Process Scheduling</span>\n",
    "As processes enter the system, they are put into a job queue, which consists of all processes in the system. The processes that are residing in main memory and are ready and waiting to execute are kept on a list called the ready queue.\n",
    "\n",
    "A common representation of process scheduling is a queueing diagram.\n",
    "\n",
    "A new process is initially put in the ready queue. It waits there until it is selected for execution, or is dispatched. Once the process is allocated the CPU and is executing, one of several events could occur:\n",
    "- The process could issue an I/0 request and then be placed in an I/0 queue.\n",
    "- The process could create a new subprocess and wait for the subprocess's termination.\n",
    "- The process could be removed forcibly from the CPU, as a result of an interrupt, and be put back in the ready queue.\n",
    "\n",
    "\n",
    "A process migrates among the various scheduling queues throughout its lifetime. The operating system must select, for scheduling purposes, processes from these queues in some fashion. The selection process is carried out by the appropriate scheduler.\n",
    "\n",
    "Often, in a batch system, more processes are submitted than can be executed immediately. These processes are spooled to a mass-storage device (typically a disk), where they are kept for later execution. The long-term scheduler, or job scheduler, selects processes from this pool and loads them into memory for execution. The short-term scheduler, or CPU scheduler, selects from among the processes that are ready to execute and allocates the CPU to one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\">3.3 Operations on Processes</span>\n",
    "The processes in most systems can execute concurrently, and they may be created and deleted dynamically.\n",
    "\n",
    "A process may create several new processes, via a create-process system call, during the course of execution. The creating process is called a parent process, and the new processes are called the children of that process. Each of these new processes may in turn create other processes, forming a tree of processes.\n",
    "\n",
    "Most operating systems identify processes according to a unique process identifier (or pid), which is typically an integer number.\n",
    "\n",
    "In general, a process will need certain resources (CPU time, memory, files, I/0 devices) to accomplish its task. When a process creates a subprocess, that subprocess may be able to obtain its resources directly from the operating system, or it may be constrained to a subset of the resources of the parent process. The parent may have to partition its resources among its children, or it may be able to share some resources (such as ncemory or files) among several of its children. Restricting a child process to a subset of the parent's resources prevents any process from overloading the system by creating too many subprocesses.\n",
    "\n",
    "When a process creates a new process, two possibilities exist in terms of execution:\n",
    "1. The parent continues to execute concurrently with its children.\n",
    "2. The parent waits until some or all of its children have terminated.\n",
    "\n",
    "There are also two possibilities in terms of the address space of the new process:\n",
    "1. The child process is a duplicate of the parent process (it has the same program and data as the parent).\n",
    "2. The child process has a new program loaded into it.\n",
    "\n",
    "A process terminates when it finishes executing its final statement and asks the operating system to delete it.\n",
    "\n",
    "Termination can occur in other circumstances as welL A process can cause the termination of another process via an appropriate system call. Usually, such a system call can be invoked only by the parent of the process that is to be terminated. Otherwise, users could arbitrarily kill each other's jobs. Note that a parent needs to know the identities of its children. Thus, when one process creates a new process, the identity of the newly created process is passed to the parent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\">3.4 Interprocess Communication</span>\n",
    "A process is independent if it cannot affect or be affected by the other processes executing in the system. A process is cooperating if it can affect or be affected by the other processes executing in the system.\n",
    "\n",
    "Interprocess communication using shared memory requires communicating processes to establish a region of shared memory. Typically, a shared-memory region resides in the address space of the process creating the shared- memory segment. Other processes that wish to communicate using this shared- memory segment must attach it to their address space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Chapter 4 Multithreaded Programming</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\">4.1 Overview</span>\n",
    "A thread is a basic unit of CPU utilization; it comprises a thread ID, a program counter, a register set, and a stack. It shares with other threads belonging to the same process its code section, data section, and other operating-system resources, such as open files and signals. A traditional (or heavrvveighl:) process has a single thread of control. If a process has multiple threads of control, it can perform more than one task at a time.\n",
    "\n",
    "The benefits of multithreaded programming can be broken down into four major categories:\n",
    "1. Responsiveness. Multithreading an interactive application may allow a program to continue running even if part of it is blocked or is performing a lengthy operation, thereby increasing responsiveness to the user.\n",
    "2. Resource sharing. Processes may only share resources through techniques such as shared memory or message passing. Such techniques must be explicitly arranged by the programmer. However, threads share the memory and the resources of the process to which they belong by default. The benefit of sharing code and data is that it allows an application to have several different threads of activity within the same address space.\n",
    "3. Economy. Allocating memory and resources for process creation is costly. Because threads share the resources of the process to which they belong, it is more economical to create and context-switch threads.\n",
    "4. Scalability. The benefits of multithreading can be greatly increased in a multiprocessor architecture, where threads may be running in parallel on different processors. A single-threaded process can only run on one processor, regardless how many are available. Multithreading on a multi-CPU machine increases parallelism.\n",
    "\n",
    "Challenges in programming for multicore systems:\n",
    "1. Dividing activities. This involves examining applications to find areas that can be divided into separate, concurrent tasks and thus can run in parallel on individual cores.\n",
    "2. Balance. While identifying tasks that can run in parallel, programmers must also ensure that the tasks perform equal work of equal value. In some instances, a certain task may not contribute as much value to the overall process as other tasks; using a separate execution core to run that task may not be worth the cost.\n",
    "3. Data splitting. Just as applications are divided into separate tasks, the data accessed and manipulated by the tasks must be divided to run on separate cores.\n",
    "4. Data dependency. The data accessed by the tasks must be examined for dependencies between two or more tasks. In instances where one task depends on data from another, programmers must ensure that the execution of the tasks is synchronized to accommodate the data dependency.\n",
    "5. Testing and debugging. When a program is running in parallel on multiple cores, there are many different execution paths. Testing and debugging such concurrent programs is inherently more difficult than testing and debugging single-threaded applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

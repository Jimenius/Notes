{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Game Theory</span>\n",
    "Platform: Coursera\n",
    "\n",
    "Institutions: Stanford University, University of British Columbia\n",
    "\n",
    "Instructors: Mathew O. Jackson, Kevin Leyton-Brown, Yoav Shoham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Week 1</span>\n",
    "Game Theory concerns about strategic interactions between self-interested people.\n",
    "##### <span style=\"color:green\">Key concepts</span>\n",
    "Self-interested Agents:\n",
    "- have own description of states of the world\n",
    "- act based on the description (to maximize expected utility). \n",
    "\n",
    "Utility function:\n",
    "- quantifies degree of preference across alternatives\n",
    "\n",
    "Normal Form:\n",
    "- lists payoffs as a function of actions\n",
    "- as if players move simultaneously\n",
    "\n",
    "Extensive Form:\n",
    "- includes timing of moves\n",
    "- as if players move sequentially, represented as a tree\n",
    "- keeps track of each player knows when he or she makes each decision\n",
    "\n",
    "Players: $N={1,...,n}$\n",
    "\n",
    "Action set: $A_i$ for player i\n",
    "\n",
    "Action profile: $a=(a_1,...,a_n)\\in A=A_1\\times...\\times A_n$\n",
    "\n",
    "Utility function: $u_i:A\\mapsto \\mathbb{R}$\n",
    "\n",
    "Profile of utility functions: $u=(u_1,...,u_n)$\n",
    "##### <span style=\"color:green\">Games</span>\n",
    "Games of pure competition: \n",
    "- Two players have opposed interests.\n",
    "- $\\forall a\\in A, u_1(a)+u_2(a)=c$\n",
    "- zero-sum game as a special case\n",
    "\n",
    "Games of cooperation:\n",
    "- Plyaers have the same interests.\n",
    "- $\\forall a\\in A,i,j, u_i(a)=u_j(a)$\n",
    "\n",
    "##### <span style=\"color:green\">Nash Equilibrium</span>\n",
    "$$a_{-i}=<a_1,...,a_{i-1},a_{i+1},...,a_n>$$\n",
    "It means every action except Player i.\n",
    "\n",
    "Best Response:\n",
    "\n",
    "$$a^*_i\\in BR(a_{-i}),iff\\forall a_i\\in A_i,u_i(a^*_i,a_{-i})\\geqslant u_i(a_i,a_{-i})$$\n",
    "\n",
    "Pure Strategy Nash Equilibrium:\n",
    "$$\\forall i,a_i\\in BR(a_{-i})$$\n",
    "\n",
    "$s_i$ strictly dominates $s'_i$ if $\\forall s_{-i}\\in S_{-i}, u_i(s_i,s_{-i})>u_i(s'_i,s_{-i})$\n",
    "\n",
    "$s_i$ very weakly dominates $s'_i$ if $\\forall s_{-i}\\in S_{-i}, u_i(s_i,s_{-i})\\geqslant u_i(s'_i,s_{-i})$\n",
    "\n",
    "If one strategy dominates all others, it is dominant.\n",
    "\n",
    "A strategy profile consisting of dominat strategies for every player must be a Nash equilibrium.\n",
    "\n",
    "An equilibrium in strictly dominant strategies must be unique.\n",
    "##### <span style=\"color:green\">Pareto Optimality</span>\n",
    "Pareto Optimality:\n",
    "\n",
    "$o$ Pareto-dominates $o'$ when $o$ is at least as good for every agent as another outcome $o'$.\n",
    "\n",
    "An outcome $o^*$ is Pareto-optimal if there is no other outcome that Pareto-dominates it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Week 2</span>\n",
    "Sometimes it can't be optimal to play determinstically.\n",
    "##### <span style=\"color:green\">Mixed Strategies</span>\n",
    "Strategy $s_i$ for agent $i$ is probabbility distribution over the actions $A_i$.\n",
    "\n",
    "Pure Strategy: Only one action is played with positive probability.\n",
    "\n",
    "Mixed Strategy: More than one action (supports) is played with positive probability.\n",
    "\n",
    "Expected Utility:\n",
    "$$u_i(s)=\\sum_{a\\in A}u_i(a)Pr(a|s)$$\n",
    "$$Pr(a|s)=\\prod_{j\\in N}s_j(a_j)$$\n",
    "##### <span style=\"color:green\">Nash Equilibrium</span>\n",
    "Best Response:\n",
    "$$s^*_i\\in BR(s_{-i}) iff\\forall s_i\\in S_i,u_i(s^*_i,s_{-i})\\geqslant u_i(s_i,s_{-i})$$\n",
    "\n",
    "Nash Equilibrium:\n",
    "$$\\forall i,s_i\\in BR(s_{-i})$$\n",
    "\n",
    "Finite game: finite number of players and finite number of actions.\n",
    "\n",
    "> Every finite game has a Nash equilibrium.\n",
    "\n",
    "Computing Two-player Mixed Strategy Nash Equilibrium:\n",
    "- Guess supports\n",
    "- Choose one player to play a strategy that makes another player indifferent among actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Week 3</span>\n",
    "\n",
    "##### <span style=\"color:green\">Dominance & Nash Equilibrium</span>\n",
    "\n",
    "Iterated removal of strictly dominated strategies\n",
    "\n",
    "The iterated removal preserves Nash equilibria.\n",
    "\n",
    "Games are dominance solvable if they are solvable with iterated removal.\n",
    "\n",
    "The order of removal doesn't matter.\n",
    "\n",
    "$s_i\\in S_i$ is weakly dominated by $s'_i\\in S_i$ if\n",
    "$$\\forall s_{-i}\\in S_{-i}, u_i(s_i,s_{-i})\\leqslant u_i(s^*_i,s_{-i})$$\n",
    "$$\\exists s_{-i}\\in S_{-i}, u_i(s_i,s_{-i})< u_i(s^*_i,s_{-i})$$\n",
    "\n",
    "Iterated removal of weakly dominated strategies\n",
    "- The removed strategies can be best replies.\n",
    "- Order of removal can matter.\n",
    "- At least one equilibrium preserved.\n",
    "\n",
    "##### <span style=\"color:green\">Maxmin Strategies</span>\n",
    "Maxmin Strategy for Player i:\n",
    "$$argmax_{s_i}min_{s_{-i}}u_i(s_i,s_{-i})$$\n",
    "Maxmin value for Player i:\n",
    "$$max_{s_i}min_{s_{-i}}u_i(s_i,s_{-i})$$\n",
    "Minmax Strategy for Player i:\n",
    "$$argmin_{s_i}max_{s_{-i}}u_{-i}(s_i,s_{-i})$$\n",
    "Minmax value for Player i:\n",
    "$$min_{s_i}max_{s_{-i}}u_{-i}(s_i,s_{-i})$$\n",
    "> In any finite, two-player, zero-sum game,, in any Nash equilibrium each player receives a payoff that is equal to both his maxmin value and his minmax value.\n",
    "\n",
    "1. Each player's maxmin value is equal to his minmax value. The maxmin value for a player is called the value of the game.\n",
    "2. For both players, the set of maxmin strategies coincides with the set of minmax strategies.\n",
    "3. Any maxmin (minmax) strategy profile is a Nash Equilibrium. These are all Nash Equilibria. All Nash Equilibria have the same payoff vector (value of the game).\n",
    "\n",
    "Two player minmax is solvable with Linear Programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Week 4</span>\n",
    "##### <span style=\"color:green\">Extensive Form Games</span>\n",
    "The normal form game representation does not incorporate any notion of sequence, or time, of the actions of the players.\n",
    "\n",
    "Perfect information Extensive form game:\n",
    "\n",
    "Players: $N$,Actions:$A$,Choice nodes:$H$,\n",
    "\n",
    "Action functions: $\\chi:H\\mapsto 2^A$ assigns each choice node a set of possible actions\n",
    "\n",
    "Player function: $\\rho:H\\mapsto N$ tells which player is to take the action at the node\n",
    "\n",
    "Terminal nodes: $Z$\n",
    "\n",
    "Successor function: $\\sigma:H\\times A\\mapsto H\\cup Z$\n",
    "\n",
    "Utility function: $u=(u_1,...,u_n),u:Z\\mapsto \\mathbb{R}$\n",
    "\n",
    "Let $G=(N,A,H,Z,\\chi,\\rho,\\sigma,u)$ be a perfect information extensive form game,\n",
    "\n",
    "The pure strategies of player $i$ consist of the cross product:\n",
    "$$\\prod_{h\\in H,\\rho(h)=i}\\chi(h)$$\n",
    "\n",
    "This even includes choice that will never have to be made given some strategies.\n",
    "\n",
    "Extensive form game can be converted into normal form.\n",
    "\n",
    "> Every perfect information game in extensive form has a Pure Strategy Nash Equilibrium.\n",
    "##### <span style=\"color:green\">Subgame Perfection</span>\n",
    "The subgame of $G$ rooted at $h$ is the restriction of $G$ to the descendents of $H$.\n",
    "\n",
    "The set of subgames of $G$ is defined by the subgames of $G$ rooted at each of the nodes in $G$.\n",
    "\n",
    "$s$ is a subgame perfect equilibrium of $G$, iff for any subgame $G'$ of $G$, the restriction of $s$ to $G'$ is a Nash Equilibrium of $G'$.\n",
    "\n",
    "Since $G$ is its own subgame, every Subgame Perfect Equilibrium is a Nash Equilibrium.\n",
    "\n",
    "It rules out non-credible threats.\n",
    "\n",
    "Backward Induction: Identify the equilibria in the bottom-most trees, and adopt these as one moves up the tree.\n",
    "\n",
    "For zero-sum games, Backward Induction is equivalent to minimax algorithm.\n",
    "\n",
    "The process can be speeded up by pruning nodes that will never be reached in play.\n",
    "##### <span style=\"color:green\">Imperfect Information Extensive Form Games</span>\n",
    "Players can't fully observe what the opponents do.\n",
    "\n",
    "Add $I=(I_1,...,I_n)$ to perfect information games, where $I_i=(I_{i,1},...,I_{i,k_i})$ is an equivalence relation on $\\{h\\in H:\\rho(h)=i\\}$ with the property that $\\chi(h)=\\chi(h')$ and $\\rho(h)=\\rho(h')$ whenever there exists a $j$ for which $h\\in I_{i,j}$ and $h'\\in I_{i,j}$.\n",
    "\n",
    "Pure strategies of player $i$ consits of the cross product:\n",
    "$$\\prod_{I_{i,j}\\in I_i}\\chi(I_{i,j})$$\n",
    "\n",
    "Normal form games can be converted to imperfect information extensive form games, but they can't be converted to perfect information extensive form games.\n",
    "\n",
    "Imperfect information extensive form games can also be converted to Normal form games. Nash Equilibria are preserved.\n",
    "\n",
    "The games might be different when Normal form games and imperfect information extensive form games are converted to each other multiple times, but strategies and Nash Equilibria are preserved.\n",
    "\n",
    "Behavioral Strategies: Choose a pure strategy with a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Week 5</span>\n",
    "##### <span style=\"color:green\">Repeated Games</span>\n",
    "Utility function for infinitely repeated games:\n",
    "$$\\lim_{k\\to\\infty}\\sum_{j=1}^k\\frac{r_j}{k}$$\n",
    "\n",
    "Discounted Reward:\n",
    "$$\\sum_{j=1}^\\infty\\beta^j r_j$$\n",
    "\n",
    "Discount factor interpretation: The agent cares more about his well-being in the near term than in the long term.\n",
    "##### <span style=\"color:green\">Stochastic Games</span>\n",
    "- Agents repeatedly play games from a set of normal form games.\n",
    "- The game played at any iteration depends on the previous game played and on the actions taken by all agents in that game.\n",
    "\n",
    "Stochastic Games:\n",
    "\n",
    "$Q$ is a finite state of states.\n",
    "\n",
    "$N$ is a finite state of n players.\n",
    "\n",
    "$A=A_1\\times...\\times A_n$, where $A_i$ is a finite set of actions available to player $i$.\n",
    "\n",
    "$P:Q\\times A\\times Q\\mapsto [0,1]$ is the transition probability.\n",
    "\n",
    "$R=r_1,...,r_n$, where $r_i:Q\\times A\\mapsto \\mathbb{R}$ is a payoff for player $i$.\n",
    "\n",
    "Markov Decision Process is a single agent stochastic game.\n",
    "\n",
    "Fictitious Play:\n",
    "- Initialize beliefs about the opponents' strategies.\n",
    "- Each turn play a best response to the assessed strategies of the opponents.\n",
    "- Observe the opponents' actual play and update beliefs accordingly.\n",
    "\n",
    "For every $a\\in A$, $w(a)$ (can be initialized as non-zero) is the number of times the opponent has action $a$.\n",
    "\n",
    "Assess opponents' strategies with the counts.\n",
    "$$\\sigma(a)=\\frac{w(a)}{\\sum_{a'\\in A}w(a')}$$\n",
    "> If the empirical distribution of each player's streategies onverges in fictitious play, then it converges to Nash Equilibrium.\n",
    "\n",
    "> Each of the following are sufficient conditions for the empirical frequencies of play to converge in fictitious play:\n",
    "- The game is zero-sum;\n",
    "- The game is solvable by iterated elimination of strictly dominated strategies;\n",
    "- The game is a potential game;\n",
    "- The game is $2\\times n$ and has generic payoffs.\n",
    "\n",
    "Regret:\n",
    "\n",
    "The regret an agent experiences at time $t$ for not having played $s$ is:\n",
    "$$R^t(s)=\\alpha^t-\\alpha^t(s)$$\n",
    "\n",
    "\n",
    "No-regret learning rule:\n",
    "A learning rule exhibits no regret if for any pure strategy of the agent $s$ it holds that $P(R^t(s)\\leqslant 0)=1$\n",
    "##### <span style=\"color:green\">Nash Equilibrium</span>\n",
    "Nash's theorem only applies to finite games.\n",
    "\n",
    "With an infinite number of strategies, there could be an infinite number of pure-strategy equilibria.\n",
    "\n",
    "Minmax value: The amount of utility a player can get when other players play a minmax strategy against him.\n",
    "$$v_i=min_{s_{-i}\\in S{-i}}max_{s_i\\in S_i}u_i(s{-i},s_i)$$\n",
    "\n",
    "A payoff profile $r$ is enforceable if $r_i\\geqslant v_i$.\n",
    "\n",
    "A payoff profile $r$ is feasible if there exist rational, non-negative values $\\alpha_a$ such that for $\\forall i$, $r_i$ can be expressed as $\\sum_{\\alpha\\in A}\\alpha_a u_i(a)$, with $\\sum_{a\\in A}\\alpha_a =1$ \n",
    "\n",
    "Feasible: a convex, rational combination of the outcomes in $G$.\n",
    "\n",
    "Folk Theorem:\n",
    "> Consider any n-player game $G$ and any payoff vector ($r_1,...r_n$)\n",
    "1. If $r$ is the payoff in any Nash equilibrium of the infinitely repeated $G$ with average rewards, then for each player $i$, $r_i$ is enforceable.\n",
    "2. If $r$ is both feasible and enforceable, then $r$ is the payoff in some Nash equilibrium of $G$ with average rewards.\n",
    "\n",
    "> Let $a=(a_1,...,a_n)$ be a Nash Equilibrium of the stage game.\n",
    "If $a'=(a'_1,...,a'_n)$ is such that $\\forall i,u_i(a')>u_i(a)$, then there exists a discount factor $\\beta<1$, such that if $\\forall i,\\beta_i\\geqslant\\beta$, then there exists a subgame perfect equilibrium of the infinite repetition of $G$ that has $a'$ played in every period on the equilibrium path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Week 6</span>\n",
    "##### <span style=\"color:green\">Bayesian Games</span>\n",
    "Bayesian Game: A set of games that differ only in their payoffs, a common prior defined over them, and a partition structure over the games for each agent. A tuple of ($N,G,P,I$)\n",
    "\n",
    "$N$ is a set of agents\n",
    "\n",
    "$G$ is a set of games with $N$ agents each such that if $g,g'\\in G$ then for each agent $i\\in N$ the strategy space in $g$ is identical to the strategy space in $g'$\n",
    "\n",
    "$P\\in \\prod(G)$ is a common prior over games, where $\\prod(G)$ is the set of all probability distributions over $G$\n",
    "\n",
    "$I=(I_1,...,I_N)$ is a set of partitions of $G$, one for each agent.\n",
    "\n",
    "An alternative definition ($N,A,\\Theta,p,u$):\n",
    "\n",
    "$N$ is a set of agents\n",
    "\n",
    "$A=(A_1,...,A_n)$, where $A_i$ is the set of actions available to player $i$\n",
    "\n",
    "$\\Theta=(\\Theta_1,...,\\Theta_n)$, where $\\Theta_i$ is the type space of player $i$\n",
    "\n",
    "$p:\\Theta\\mapsto[0,1]$ is the common prior over types\n",
    "\n",
    "$u=(u_1,...,u_n)$ where $u_i:A\\times\\Theta\\mapsto\\mathbb{R}$ is the utility function for player $i$\n",
    "\n",
    "Bayesian (Nash) Equilibrium: A plan of action for each player as a function of types that maximize each type's expected utility\n",
    "\n",
    "Strategies:\n",
    "\n",
    "Pure strategy: $s_i:\\Theta_i\\mapsto A_i$\n",
    "\n",
    "Mixed strategy: $s_i:\\Theta_i\\mapsto\\prod(A_i)$\n",
    "\n",
    "Three standard notions of expected utility:\n",
    "1. ex-ante: The agent knows nothing about anyone's actual type.\n",
    "2. interim: The agent knows her own type but not hte types of the other agents.\n",
    "3. ex-post: The agent knows all agents' types.\n",
    "\n",
    "Iterim expected utility:\n",
    "$$EU_i(s|\\theta_i)=\\sum_{\\theta_{-i}\\in\\Theta{-i}}p(\\theta_{-i}|\\theta_i)\\sum_{a\\in A}(\\prod_{j\\in N}s_j(a_j|\\theta_j))u_i(a,\\theta_i,\\theta_{-i})$$\n",
    "\n",
    "Ex-ante expected utility:\n",
    "$$EU_i(s)=\\sum_{\\theta_i\\in\\Theta_i}p(\\theta_i)EU_i(s|\\theta_i)$$\n",
    "\n",
    "A Bayesian Equilibrium is a mixed strategy profile $s$ that satisfies:\n",
    "$$s_i\\in argmaxEU_i(s'_i,s_{-i}|\\theta_i),\\forall i, \\theta_i\\in\\Theta_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Week 7</span>\n",
    "##### <span style=\"color:green\">Coalitional Games</span>\n",
    "Coalitional Games ($N,v$):\n",
    "\n",
    "$N$ is a finite set of players.\n",
    "\n",
    "$v:2^N\\mapsto\\mathbb{R}$ associates with each coalition $S\\subseteq N$ a real-valued payoff $v(S)$ that the coalition's members can distribute among themselves. Assume that $v(\\varnothing)=0$\n",
    "\n",
    "A coalitional game is superadditive if $\\forall S,T\\subseteq N, S\\cap T=\\varnothing$, then $v(S\\cup T)\\geqslant v(S)+v(T)$.\n",
    "\n",
    "Superadditivity implies that the grand coalition ($S=N$) has the highest payoff.\n",
    "##### <span style=\"color:green\">Shapley value</span>\n",
    "Lloyd Shapley:\n",
    "> Members should receive payments or shares proportional to their marginal contributions.\n",
    "\n",
    "$i$ and $j$ are interchangeable relative to $v$ if they always contribute the same amount to every coalition of the other agents. $\\forall S$ that contains neither $i$ nor $j$, $v(S\\cup\\{i\\})=v(S\\cup\\{j\\})$.\n",
    "\n",
    "Interchangeable agents should receive the same shares or payments.\n",
    "\n",
    "$i$ is a dummy player if the amount that $i$ contributes to any coalition is 0. $\\forall S: v(S\\cup\\{i\\})=v(S)$.\n",
    "\n",
    "Dummy players should receive nothing.\n",
    "\n",
    "If we can separate a game into two parts $v=v_1+v_2$, then we should be able to decompose the payments.\n",
    "\n",
    "Shapley value divides payoffs for each player:\n",
    "$$\\phi_i(N,v)=\\frac{1}{N!}\\sum_{S\\subseteq N/\\{i\\}}|S|!(|N|-|S|-1)!(v(S\\cup\\{i\\})-v(S))$$\n",
    "\n",
    "> Given a coalitional game ($N,v$), Shapley value is the unique payoff division $x(v)=\\phi(N,v)$ that divides the full payoff of the grand coalition and that satisfies the Symmetry, Dummy player and Additivity axioms.\n",
    "##### <span style=\"color:green\">Core</span>\n",
    "The Shapley value defines a fair way of dividing the grand coalition's payment among members, yet ignores stability (Some of the members are willing to form smaller coalitions).\n",
    "\n",
    "Members are willing to form grand coalition if and only if the payment profile is drawn from core.\n",
    "\n",
    "A payoff vector $x$ is in the core of a coalitional game ($N,v$) iff\n",
    "$$\\forall S\\subseteq N, \\sum_{i\\in S}x_i\\geqslant v(S)$$\n",
    "\n",
    "The core is not always unique.\n",
    "\n",
    "A game is simple if $\\forall S\\subset N, v(S)\\in\\{0,1\\}$ (1 is a representation of success, might not be 1 indeed).\n",
    "\n",
    "A player $i$ is a veto player if $v(N/\\{i\\})=0$.\n",
    "\n",
    "> In a simple game the core is empty iff there is no veto player. If there are veto players, the core consists of all payoff vectors in which the nonveto players get 0.\n",
    "\n",
    "A game is convex if $\\forall S,T\\subset N,v(S\\cup T)\\geqslant v(S)+v(T)-v(S\\cap T)$.\n",
    "\n",
    "Convexity is a stronger condition than super additivity.\n",
    "\n",
    "> Every convex game has a nonempty core.\n",
    "\n",
    "> In every convex game, the Shapley value is in the core."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
